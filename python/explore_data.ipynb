{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.board_module as bf\n",
    "import modules.tree_module as tf\n",
    "import modules.stockfish_module as sf\n",
    "from ModelSaver import ModelSaver\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import floor, ceil\n",
    "\n",
    "# from train_nn_evaluator import EvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, datapath, sample_names, indexes=None, log_level=1):\n",
    "    \"\"\"\n",
    "    Dataset containint stockfish evaluations of chess positions. Pass in the\n",
    "    path to the samples, their names, and the indexes to load\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    self.modelsaver = ModelSaver(datapath, log_level=log_level)\n",
    "    self.log_level = log_level\n",
    "    self.positions = []\n",
    "    self.seen_values = None\n",
    "\n",
    "    self.mate_value = 50000             # value of a checkmate (units 1000 per pawn)\n",
    "    self.convert_evals_to_pawns = True  # convert evaluations from 1000 per pawn, to 1.0 per pawn\n",
    "    self.use_all_moves = True           # add in all child moves from a positions, instead of the parent\n",
    "    self.eval_squares = True            # evaluate every square in the board using my handcrafted evaluator\n",
    "    self.use_eval_normalisation = False # apply normalisation to all evaluations\n",
    "    self.norm_method = \"standard\"       # normalisation method to use, standard is mean/std scale -1/+1 bound\n",
    "    self.norm_factor = None             # normalisation factors saved for future use\n",
    "    self.board_dtype = torch.float      # datatype to use for torch tensors\n",
    "\n",
    "    self.boards = []\n",
    "    self.evals = []\n",
    "\n",
    "    # automatically get all indexes if not specified\n",
    "    if indexes is None:\n",
    "      indexes = list(range(self.modelsaver.get_recent_file(name=sample_names, \n",
    "                                                           return_int=True) + 1))\n",
    "\n",
    "    for ind in indexes:\n",
    "      newdata = self.modelsaver.load(sample_names, id=ind)\n",
    "      self.positions += newdata\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    if self.log_level >= 1:\n",
    "      print(f\"EvalDataset(): {len(indexes)} files loaded {t2 - t1:.2f} seconds\")\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.positions)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    if idx > len(self.positions):\n",
    "      raise RuntimeError(f\"EvalDataset.__getitem__() error: idx ({idx}) > number of samples (len{self.positions})\")\n",
    "    \n",
    "    return self.positions[idx]\n",
    "  \n",
    "  def FEN_to_torch(self, fen_string, move=None, eval_sqs=False):\n",
    "    \"\"\"\n",
    "    Convert an FEN string into a torch tensor board representation\n",
    "    \"\"\"\n",
    "\n",
    "    if move is None:\n",
    "      boardvec = bf.FEN_to_board_vectors(fen_string)\n",
    "    else:\n",
    "      if eval_sqs:\n",
    "        boardvec = bf.FEN_move_eval_to_board_vectors(fen_string, move)\n",
    "      else:\n",
    "        boardvec = bf.FEN_and_move_to_board_vectors(fen_string, move)\n",
    "\n",
    "    tensortype = self.board_dtype\n",
    "\n",
    "    t_wP = torch.tensor(boardvec.wP, dtype=tensortype).reshape(8, 8)\n",
    "    t_wN = torch.tensor(boardvec.wN, dtype=tensortype).reshape(8, 8)\n",
    "    t_wB = torch.tensor(boardvec.wB, dtype=tensortype).reshape(8, 8)\n",
    "    t_wR = torch.tensor(boardvec.wR, dtype=tensortype).reshape(8, 8)\n",
    "    t_wQ = torch.tensor(boardvec.wQ, dtype=tensortype).reshape(8, 8)\n",
    "    t_wK = torch.tensor(boardvec.wK, dtype=tensortype).reshape(8, 8)\n",
    "    t_bP = torch.tensor(boardvec.bP, dtype=tensortype).reshape(8, 8)\n",
    "    t_bN = torch.tensor(boardvec.bN, dtype=tensortype).reshape(8, 8)\n",
    "    t_bB = torch.tensor(boardvec.bB, dtype=tensortype).reshape(8, 8)\n",
    "    t_bR = torch.tensor(boardvec.bR, dtype=tensortype).reshape(8, 8)\n",
    "    t_bQ = torch.tensor(boardvec.bQ, dtype=tensortype).reshape(8, 8)\n",
    "    t_bK = torch.tensor(boardvec.bK, dtype=tensortype).reshape(8, 8)\n",
    "    t_wKS = torch.tensor(boardvec.wKS, dtype=tensortype).reshape(8, 8)\n",
    "    t_wQS = torch.tensor(boardvec.wQS, dtype=tensortype).reshape(8, 8)\n",
    "    t_bKS = torch.tensor(boardvec.bKS, dtype=tensortype).reshape(8, 8)\n",
    "    t_bQS = torch.tensor(boardvec.bQS, dtype=tensortype).reshape(8, 8)\n",
    "    t_colour = torch.tensor(boardvec.colour, dtype=tensortype).reshape(8, 8)\n",
    "\n",
    "    # ignore these as no data in them currently, just wasted space\n",
    "    # t_total_moves = torch.tensor(boardvec.total_moves, dtype=tensortype).reshape(8, 8)\n",
    "    # t_no_take_ply = torch.tensor(boardvec.no_take_ply, dtype=tensortype).reshape(8, 8)\n",
    "\n",
    "    board_tensor = torch.stack((\n",
    "      t_wP,\n",
    "      t_wN,\n",
    "      t_wB,\n",
    "      t_wR,\n",
    "      t_wQ,\n",
    "      t_wK,\n",
    "      t_bP,\n",
    "      t_bN,\n",
    "      t_bB,\n",
    "      t_bR,\n",
    "      t_bQ,\n",
    "      t_bK,\n",
    "      t_wKS,\n",
    "      t_wQS,\n",
    "      t_bKS,\n",
    "      t_bQS,\n",
    "      t_colour,\n",
    "      # t_total_moves,\n",
    "      # t_no_take_ply,\n",
    "    ), dim=0)\n",
    "\n",
    "    if eval_sqs:\n",
    "      sq_evals = torch.tensor(boardvec.sq_evals, dtype=float)\n",
    "      if self.convert_evals_to_pawns:\n",
    "        sq_evals *= 1e-3\n",
    "      return board_tensor, sq_evals\n",
    "    else:\n",
    "      return board_tensor\n",
    "  \n",
    "  def print_board_tensor(self, board_tensor):\n",
    "    \"\"\"\n",
    "    Print the elements of the board tensor\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Board tensor shape:\", board_tensor.shape)\n",
    "    print(\"White pawns\", board_tensor[0])\n",
    "    print(\"White knights\", board_tensor[1])\n",
    "    print(\"White bishops\", board_tensor[2])\n",
    "    print(\"White rooks\", board_tensor[3])\n",
    "    print(\"White queen\", board_tensor[4])\n",
    "    print(\"White king\", board_tensor[5])\n",
    "    print(\"Black pawns\", board_tensor[6])\n",
    "    print(\"Black knights\", board_tensor[7])\n",
    "    print(\"Black bishops\", board_tensor[8])\n",
    "    print(\"Black rooks\", board_tensor[9])\n",
    "    print(\"Black queen\", board_tensor[10])\n",
    "    print(\"Black king\", board_tensor[11])\n",
    "    print(\"White castles KS\", board_tensor[12])\n",
    "    print(\"White castles QS\", board_tensor[13])\n",
    "    print(\"Black castles KS\", board_tensor[14])\n",
    "    print(\"Black castles QS\", board_tensor[15])\n",
    "    print(\"colour\", board_tensor[16])\n",
    "    print(\"total moves\", board_tensor[17])\n",
    "    print(\"no take ply\", board_tensor[18])\n",
    "\n",
    "    return\n",
    "\n",
    "  def normalise_evaluations(self):\n",
    "    \"\"\"\n",
    "    Normalise the evaluations to zero mean and unit variance, and save the scaling\n",
    "    \"\"\"\n",
    "    if self.norm_method == \"minmax\":\n",
    "      max_value = torch.max(-1 * torch.min(self.evals), torch.max(self.evals))\n",
    "      self.norm_factor = max_value\n",
    "      self.evals /= self.norm_factor\n",
    "      if self.log_level > 0:\n",
    "        print(f\"Normalised evaluations, maximum value was {max_value}, now is {torch.max(-1 * torch.min(self.evals), torch.max(self.evals))}\")\n",
    "    \n",
    "    elif self.norm_method == \"standard\":\n",
    "      max_value = torch.max(-1 * torch.min(self.evals), torch.max(self.evals))\n",
    "      mean = self.evals.mean()\n",
    "      std = self.evals.std()\n",
    "      self.evals = (self.evals - mean) / std\n",
    "      new_max = torch.max(-1 * torch.min(self.evals), torch.max(self.evals))\n",
    "      self.evals /= new_max\n",
    "      self.norm_factor = (new_max, mean, std)\n",
    "      if self.log_level > 0:\n",
    "        print(f\"Normalised evaluations, max_value = {max_value:.3f} (max used = {new_max:.3f}), mean = {mean.item():.3f}, std = {std.item():.3f}, now max value is {torch.max(-1 * torch.min(self.evals), torch.max(self.evals)):.3f}, mean is {self.evals.mean().item():.3f} and std is {self.evals.std().item():.3f}\")\n",
    "\n",
    "  def denomormalise_evaluation(self, value=None, all=False):\n",
    "    \"\"\"\n",
    "    Convert a single value back to regular units (or do it for all saved values)\n",
    "    \"\"\"\n",
    "\n",
    "    if self.norm_method == \"minmax\":\n",
    "      if all:\n",
    "        self.evals *= self.norm_factor\n",
    "      elif value is not None:\n",
    "        return value * self.norm_factor\n",
    "      else:\n",
    "        raise RuntimeError(\"EvalDataset.denormalise_evaluations() error: all=False and value=None, incorrect function inputs\")\n",
    "    \n",
    "    if self.norm_method == \"standard\":\n",
    "      if all:\n",
    "        self.evals = (self.evals * self.norm_factor[0] * self.norm_factor[2]) + self.norm_factor[1]\n",
    "      elif value is not None:\n",
    "        return (value * self.norm_factor[0] * self.norm_factor[2]) + self.norm_factor[1]\n",
    "      else:\n",
    "        raise RuntimeError(\"EvalDataset.denormalise_evaluations() error: all=False and value=None, incorrect function inputs\")\n",
    "\n",
    "  def to_torch(self):\n",
    "    \"\"\"\n",
    "    Convert dataset into torch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    if len(self.positions) == 0:\n",
    "      print(\"EvalDataset.to_torch() warning: len(self.positions) == 0, nothing done\")\n",
    "      return\n",
    "\n",
    "    # get the shape of the board tensors\n",
    "    example = self.FEN_to_torch(self.positions[0].fen_string)\n",
    "    num_pos = len(self.positions)\n",
    "\n",
    "    if self.use_all_moves:\n",
    "      # count how many positions we will have\n",
    "      num_lines = 0\n",
    "      for i in range(num_pos):\n",
    "        num_lines += len(self.positions[i].move_vector)\n",
    "      self.boards = torch.zeros((num_lines, *example.shape), dtype=example.dtype)\n",
    "      self.evals = torch.zeros(num_lines, dtype=torch.float)\n",
    "      if self.eval_squares:\n",
    "        self.square_evals = torch.zeros((num_lines, 64), dtype=torch.float)\n",
    "      add_ind = 0\n",
    "      error_moves = 0\n",
    "      if self.log_level > 0:\n",
    "        print(f\"self.use_all_moves = True, found {num_lines} lines (emerging from {num_pos} positions)\")\n",
    "    else:\n",
    "      self.boards = torch.zeros((num_pos, *example.shape), dtype=example.dtype)\n",
    "      self.evals = torch.zeros(num_pos, dtype=torch.float)\n",
    "    \n",
    "    for i in range(num_pos):\n",
    "\n",
    "      if self.use_all_moves:\n",
    "        # loop through all moves and add those boards\n",
    "        for j in range(len(self.positions[i].move_vector)):\n",
    "          if self.positions[i].move_vector[j].move_letters == \"pv\":\n",
    "            error_moves += 1\n",
    "            num_lines -= 1\n",
    "            continue\n",
    "          if self.eval_squares:\n",
    "            self.boards[add_ind], self.square_evals[add_ind] = self.FEN_to_torch(\n",
    "              self.positions[i].fen_string, self.positions[i].move_vector[j].move_letters, self.eval_squares\n",
    "            )\n",
    "          else:\n",
    "            self.boards[add_ind] = self.FEN_to_torch(self.positions[i].fen_string,\n",
    "                                                    self.positions[i].move_vector[j].move_letters)\n",
    "          if self.positions[i].move_vector[j].eval == \"mate\":\n",
    "            if not bf.is_white_next_FEN(self.positions[i].fen_string):\n",
    "              self.evals[add_ind] = -self.mate_value\n",
    "            else:\n",
    "              self.evals[add_ind] = self.mate_value\n",
    "          else:\n",
    "            self.evals[add_ind] = self.positions[i].move_vector[j].eval\n",
    "          if self.convert_evals_to_pawns:\n",
    "            self.evals[add_ind] *= 1e-3\n",
    "          add_ind += 1\n",
    "\n",
    "      else:\n",
    "        self.boards[i] = self.FEN_to_torch(self.positions[i].fen_string)\n",
    "        if self.positions[i].eval == \"mate\":\n",
    "          if bf.is_white_next_FEN(self.positions[i].fen_string):\n",
    "            self.evals[i] = -self.mate_value\n",
    "          else:\n",
    "            self.evals[i] = self.mate_value\n",
    "        else:\n",
    "          self.evals[i] = self.positions[i].eval\n",
    "        if self.convert_evals_to_pawns:\n",
    "          self.evals[i] *= 1e-3\n",
    "\n",
    "    if self.use_all_moves:\n",
    "      if error_moves > 0:\n",
    "        self.boards = self.boards[:num_lines, :, :]\n",
    "        self.evals = self.evals[:num_lines]\n",
    "        if self.log_level > 0:\n",
    "          print(f\"The number of error moves was: {error_moves}, out of {num_lines + error_moves} lines. New vector length = {self.evals.shape}\")\n",
    "\n",
    "    # # for testing only\n",
    "    # print(\"Shape of self.boards\", self.boards.shape)\n",
    "    # x = num_pos // 2\n",
    "    # bf.print_FEN_board(self.positions[x].fen_string)\n",
    "    # self.print_board_tensor(self.boards[x])\n",
    "\n",
    "    if self.use_eval_normalisation:\n",
    "      if self.log_level > 0:\n",
    "        print(\"EvalDataset() is applying normalisation to self.evals\")\n",
    "      self.normalise_evaluations()\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    if self.log_level > 0:\n",
    "      if self.use_all_moves:\n",
    "        total_num = num_lines\n",
    "      else: total_num = num_pos\n",
    "      print(f\"EvalDataset(): {total_num} positions converted in {t2 - t1:.2f} seconds, average {((t2 - t1) / total_num) * 1e3:.3f} ms per position\")\n",
    "\n",
    "    return\n",
    "  \n",
    "  def check_duplicates(self, remove=False, wipe_seen=True):\n",
    "    \"\"\"\n",
    "    Check the number (and potentially remove) duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # remove duplicates\n",
    "    if wipe_seen:\n",
    "      self.seen_values = set()\n",
    "    elif self.seen_values is None:\n",
    "      self.seen_values = set()\n",
    "      \n",
    "    unique_positions = []\n",
    "\n",
    "    for position in self.positions:\n",
    "      if position.fen_string not in self.seen_values:\n",
    "        self.seen_values.add(position.fen_string)\n",
    "        unique_positions.append(position)\n",
    "\n",
    "    num_duplicates = len(self.positions) - len(unique_positions)\n",
    "\n",
    "    # now if we want remove the duplicates\n",
    "    if remove: self.positions = unique_positions\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    if self.log_level >= 1:\n",
    "      print(f\"EvalDataset(): {num_duplicates} duplicates found in {t2 - t1:.2f} seconds{', and removed' if remove else ''}\")\n",
    "\n",
    "    return num_duplicates\n",
    "  \n",
    "  def check_mate_positions(self, remove=False):\n",
    "    \"\"\"\n",
    "    Check the number (and potentially remove) mate positions\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    no_mate_positions = []\n",
    "\n",
    "    # loop backwards over all positions checking for mate\n",
    "    for i in range(len(self.positions) - 1, -1, -1):\n",
    "      if self.positions[i].eval != \"mate\":\n",
    "        no_mate_positions.append(self.positions[i])\n",
    "\n",
    "    num_mates = len(self.positions) - len(no_mate_positions)\n",
    "\n",
    "    # now if we want remove the duplicates\n",
    "    if remove: self.positions = no_mate_positions\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    if self.log_level >= 1:\n",
    "      print(f\"EvalDataset(): {num_mates} mate positions found in {t2 - t1:.2f} seconds{', and removed' if remove else ''}\")\n",
    "\n",
    "    return num_mates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /home/luke/chess/python/gamedata/samples/random_n=4096_sample_140.lz4 with pickle ... finished\n",
      "EvalDataset(): 1 files loaded 0.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# load in the entire dataset\n",
    "num_rand = 4096\n",
    "datapath = \"/home/luke/chess/python/gamedata/samples\"\n",
    "eval_file_template = \"random_n={0}_sample\"\n",
    "inds = list(range(1))\n",
    "log_level = 1\n",
    "dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                      indexes=inds, log_level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positions = 4096\n",
      "EvalDataset(): 186 duplicates found in 0.00 seconds\n",
      "EvalDataset(): 6 mate positions found in 0.00 seconds\n",
      "Proportion of duplicates = 4.5 %\n",
      "Proportion of mate positions = 0.1 %\n",
      "REMOVING MATES AND DUPLICATES\n",
      "EvalDataset(): 186 duplicates found in 0.00 seconds, and removed\n",
      "EvalDataset(): 6 mate positions found in 0.00 seconds, and removed\n",
      "self.use_all_moves = True, found 113778 lines (emerging from 3904 positions)\n",
      "EvalDataset(): 113778 positions converted in 28.59 seconds, average 0.251 ms per position\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of positions = {len(dataset)}\")\n",
    "num_duplicates = dataset.check_duplicates()\n",
    "num_mates = dataset.check_mate_positions()\n",
    "print(f\"Proportion of duplicates = {(num_duplicates / len(dataset))*100:.1f} %\")\n",
    "print(f\"Proportion of mate positions = {(num_mates / len(dataset))*100:.1f} %\")\n",
    "\n",
    "# prepare the dataset\n",
    "print(\"REMOVING MATES AND DUPLICATES\")\n",
    "num_duplicates = dataset.check_duplicates(remove=True)\n",
    "num_mates = dataset.check_mate_positions(remove=True)\n",
    "dataset.board_dtype = torch.float\n",
    "dataset.to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savenew = False\n",
    "\n",
    "if savenew:\n",
    "\n",
    "  dataset_name = \"datasetv2\"\n",
    "  file_name = \"data\"\n",
    "  ind_per = 2               # indexes per slice of the dataset\n",
    "  total_index = 140         # largest index number of gamedata/samples file\n",
    "  prevent_duplicates = True # prevent duplicates across the entire set, not just in each slice\n",
    "  savetorchonly = False     # save only the finalised torch tensors\n",
    "  savetorchtoo = True       # save also a torch version of the dataset\n",
    "  log_level = 1             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "\n",
    "  num_sets = total_index // ind_per\n",
    "  if prevent_duplicates: seen_values = set()\n",
    "\n",
    "  datasaver = ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  datasaver.new_folder(dataset_name)\n",
    "\n",
    "  for ind in range(num_sets):\n",
    "\n",
    "    print(\"Loading set\", ind + 1, \"/\", num_sets)\n",
    "    indexes = list(range(ind * ind_per + 1, ((ind + 1) * ind_per) + 1))\n",
    "    dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                          indexes=indexes, log_level=log_level)\n",
    "    if prevent_duplicates: dataset.seen_values = seen_values\n",
    "    num_duplicates = dataset.check_duplicates(remove=True, wipe_seen=not prevent_duplicates)\n",
    "    num_mates = dataset.check_mate_positions(remove=True)\n",
    "    dataset.board_dtype = torch.float\n",
    "    dataset.to_torch()\n",
    "    if savetorchonly or savetorchtoo:\n",
    "      if dataset.eval_squares:\n",
    "        datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals, dataset.square_evals])\n",
    "      else:\n",
    "        datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals])\n",
    "    elif not savetorchonly:\n",
    "      datasaver.save(file_name, dataset)\n",
    "    if prevent_duplicates: seen_values = dataset.seen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "savenew_randomised = False\n",
    "\n",
    "if savenew_randomised:\n",
    "\n",
    "  dataset_name = \"delete\"\n",
    "  file_name = \"data\"\n",
    "  num_per = 200_000         # number of lines per saved file\n",
    "  total_index = 140         # largest index number of gamedata/samples file\n",
    "  prevent_duplicates = True # prevent duplicates across the entire set, not just in each slice\n",
    "  log_level = 1             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "\n",
    "  datasaver = ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  datasaver.new_folder(dataset_name)\n",
    "\n",
    "  indexes = list(range(1, total_index + 1))\n",
    "  dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                          indexes=indexes, log_level=log_level)\n",
    "  num_duplicates = dataset.check_duplicates(remove=True)\n",
    "  num_mates = dataset.check_mate_positions(remove=True)\n",
    "  dataset.to_torch()\n",
    "\n",
    "  # now randomise a selection of the indexes\n",
    "  num_boards = len(dataset.evals)\n",
    "  indexes = list(range(num_boards))\n",
    "  random.shuffle(indexes)\n",
    "\n",
    "  num_files = num_boards // num_per\n",
    "  ind = 0\n",
    "\n",
    "  print(\"num_files is\", num_files)\n",
    "  print(\"num_boards is\", num_boards)\n",
    "  \n",
    "  for n in range(num_files):\n",
    "\n",
    "    boards = torch.zeros((num_per, *dataset.boards[0].shape))\n",
    "    evals = torch.zeros((num_per))\n",
    "    sq_evals = torch.zeros((num_per, *dataset.square_evals[0].shape))\n",
    "\n",
    "    for i in range(num_per):\n",
    "\n",
    "      boards[i] = dataset.boards[indexes[ind]]\n",
    "      evals[i] = dataset.evals[indexes[ind]]\n",
    "      sq_evals[i] = dataset.square_evals[indexes[ind]]\n",
    "\n",
    "      # increment to the next random index\n",
    "      ind += 1\n",
    "\n",
    "    datasaver.save(file_name + \"_torch\", [boards, evals, sq_evals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data, factors, clip=None):\n",
    "  \"\"\"\n",
    "  Normalise data based on [max, mean, std]\n",
    "  \"\"\"\n",
    "  max, mean, std = factors\n",
    "  d = ((data - mean) / std) / max\n",
    "  if clip is not None:\n",
    "    d = torch.clip(d, min=-clip, max=clip)\n",
    "  return d\n",
    "\n",
    "examine = False\n",
    "\n",
    "if examine:\n",
    "\n",
    "  factors = [23.927, -0.240, 0.355]\n",
    "  factors = [3, -0.240, 0.355]\n",
    "  norm_evals = normalise_data(dataset.evals, factors, clip=1)\n",
    "\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.hist(norm_evals.numpy(), bins=50)\n",
    "  plt.show()\n",
    "\n",
    "  print(torch.max(dataset.evals))\n",
    "  print(torch.min(dataset.evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoardCNN(nn.Module):\n",
    "\n",
    "  name = \"BoardCNN\"\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(BoardCNN, self).__init__()\n",
    "\n",
    "    self.board_cnn = nn.Sequential(\n",
    "\n",
    "      # Layer 1\n",
    "      nn.Conv2d(in_channels=19, out_channels=32, kernel_size=3, padding=1),  # Conv layer\n",
    "      nn.ReLU(),                                                             # Activation\n",
    "      nn.MaxPool2d(kernel_size=2),                                           # Pooling (output size: 32 x 4 x 4)\n",
    "\n",
    "      # Layer 2\n",
    "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2),                                           # Pooling (output size: 64 x 2 x 2)\n",
    "\n",
    "      # Layer 3\n",
    "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2),                                           # Pooling (output size: 128 x 1 x 1)\n",
    "\n",
    "      # Flatten layer to transition to fully connected\n",
    "      nn.Flatten(),\n",
    "\n",
    "      # two fully connected layers to produce a single output\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 1),\n",
    "  )\n",
    "\n",
    "  def forward(self, board):\n",
    "    board = board.to(self.device)\n",
    "    x = self.board_cnn(board)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.conv2 = nn.Sequential(\n",
    "      nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "      nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "    self.downsample = downsample\n",
    "    self.relu = nn.ReLU()\n",
    "    self.out_channels = out_channels\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    out = self.conv1(x)\n",
    "    out = self.conv2(out)\n",
    "    if self.downsample:\n",
    "      residual = self.downsample(x)\n",
    "    out += residual\n",
    "    out = self.relu(out)\n",
    "    return out\n",
    "  \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "  def __init__(self, block, layers, num_classes = 10):\n",
    "    super(ResNet, self).__init__()\n",
    "    self.inplanes = 64\n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "    self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "    self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "    self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "    self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "    self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "    self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "  def _make_layer(self, block, planes, blocks, stride=1):\n",
    "    downsample = None\n",
    "    if stride != 1 or self.inplanes != planes:\n",
    "      downsample = nn.Sequential(\n",
    "          nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "          nn.BatchNorm2d(planes),\n",
    "      )\n",
    "    layers = []\n",
    "    layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "    self.inplanes = planes\n",
    "    for i in range(1, blocks):\n",
    "      layers.append(block(self.inplanes, planes))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.layer0(x)\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class ChessNet(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, num_blocks=3):\n",
    "\n",
    "    super(ChessNet, self).__init__()\n",
    "\n",
    "    self.in_channels = in_channels\n",
    "    c_in = in_channels\n",
    "\n",
    "    blocks = [ResidualBlock(c_in, c_in) for i in range(num_blocks)]\n",
    "\n",
    "    self.board_cnn = nn.Sequential(\n",
    "      *blocks,\n",
    "      nn.Sequential(nn.Flatten(), nn.Linear(c_in * 8 * 8, c_in), nn.ReLU()),\n",
    "      nn.Linear(c_in, 1),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    for l in self.layers:\n",
    "      x = l(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_x, data_y, epochs=1, lr=5e-5, device=\"cuda\"):\n",
    "  \"\"\"\n",
    "  Perform a training epoch for a given network based on data inputs\n",
    "  data_x, and correct outputs data_y\n",
    "  \"\"\"\n",
    "\n",
    "  # move onto the specified device\n",
    "  net.board_cnn.to(device)\n",
    "  data_x = data_x.to(device)\n",
    "  data_y = data_y.to(device)\n",
    "\n",
    "  # put the model in training mode\n",
    "  net.board_cnn.train()\n",
    "\n",
    "  lossfcn = nn.MSELoss()\n",
    "  optim = torch.optim.Adam(net.board_cnn.parameters(), lr=lr)\n",
    "\n",
    "  batch_size = 64\n",
    "  num_batches = len(data_x) // batch_size\n",
    "\n",
    "  for i in range(epochs):\n",
    "\n",
    "    print(f\"Starting epoch {i + 1}. There will be {num_batches} batches\")\n",
    "\n",
    "    rand_idx = torch.randperm(data_x.shape[0])\n",
    "    avg_loss = 0\n",
    "\n",
    "    for n in range(num_batches):\n",
    "\n",
    "      batch_x = data_x[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "      batch_y = data_y[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "      # use the model for a prediction and calculate loss\n",
    "      net_y = net.board_cnn(batch_x)\n",
    "      loss = lossfcn(net_y.squeeze(1), batch_y)\n",
    "\n",
    "      # backpropagate\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      optim.zero_grad()\n",
    "\n",
    "      avg_loss += loss.item()\n",
    "\n",
    "      # if n % 500 == 0:\n",
    "      #   print(f\"Loss is {(avg_loss / (n + 1)) * 1000:.3f}, epoch {i + 1}, batch {n + 1} / {num_batches}\")\n",
    "    \n",
    "    print(f\"Loss is {(avg_loss / (num_batches * batch_size)) * 1000:.3f}, at end of epoch {i + 1}\")\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexamine = False\n",
    "\n",
    "if rexamine:\n",
    "\n",
    "  # load all of the dataset files to examine the data distribution\n",
    "  max_values = []\n",
    "  mean_values = []\n",
    "  std_values = []\n",
    "  for i in range(1, 11):\n",
    "    this_data = datasaver.load(\"datasetv1\", id=i)\n",
    "    this_data.normalise_evaluations()\n",
    "    max_values.append(this_data.norm_factor[0])\n",
    "    mean_values.append(this_data.norm_factor[1])\n",
    "    std_values.append(this_data.norm_factor[2])\n",
    "\n",
    "  true_max = np.max(max_values)\n",
    "  avg_mean = np.mean(mean_values)\n",
    "  avg_std = np.mean(std_values)\n",
    "\n",
    "  print(f\"True max = {true_max:.3f}, true mean = {avg_mean:.3f}, average std = {avg_std:.3f}\")\n",
    "\n",
    "  norm_factors = [true_max, avg_mean, avg_std]\n",
    "\n",
    "else:\n",
    "  # True max = 23.927, true mean = -0.240, average std = 0.355\n",
    "  norm_factors = [23.927, -0.240, 0.355]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data, factors):\n",
    "  \"\"\"\n",
    "  Normalise data based on [max, mean, std]\n",
    "  \"\"\"\n",
    "  max, mean, std = factors\n",
    "  return ((data - mean) / std) / max\n",
    "\n",
    "def denormalise_data(data, factors):\n",
    "  \"\"\"\n",
    "  Undo normalisation based on [max, mean, std]\n",
    "  \"\"\"\n",
    "  max, mean, std = factors\n",
    "  return (data * max * std) + mean\n",
    "\n",
    "def train_procedure(net, dataname, dataloader, data_inds, norm_factors,\n",
    "                    epochs=1, lr=1e-7, device=\"cuda\", batch_size=64,\n",
    "                    loss_style=\"MSE\"):\n",
    "  \"\"\"\n",
    "  Perform a training epoch for a given network based on data inputs\n",
    "  data_x, and correct outputs data_y\n",
    "  \"\"\"\n",
    "\n",
    "  # move onto the specified device\n",
    "  net.board_cnn.to(device)\n",
    "\n",
    "  # put the model in training mode\n",
    "  net.board_cnn.train()\n",
    "\n",
    "  if loss_style.lower() == \"mse\":\n",
    "    lossfcn = nn.MSELoss()\n",
    "  elif loss_style.lower() == \"l1\":\n",
    "    lossfcn = nn.L1Loss()\n",
    "  elif loss_style.lower() == \"huber\":\n",
    "    lossfcn = nn.HuberLoss()\n",
    "  else:\n",
    "    raise RuntimeError(f\"train_procedure() error: loss_style = {loss_style} not recognised\")\n",
    "\n",
    "  optim = torch.optim.Adam(net.board_cnn.parameters(), lr=lr)\n",
    "  \n",
    "  # each epoch, cover the entire training dataset\n",
    "  for i in range(epochs):\n",
    "\n",
    "    print(f\"Starting epoch {i + 1}.\")\n",
    "    total_batches = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # load the dataset in a series of slices\n",
    "    for slice_num, j in enumerate(data_inds):\n",
    "\n",
    "      # load this segment of the dataset\n",
    "      dataset = dataloader.load(dataname, id=j)\n",
    "      data_x = dataset.boards\n",
    "      data_y = dataset.evals\n",
    "\n",
    "      # import sys\n",
    "      # print(\"The size in bytes of data_x\", sys.getsizeof(data_x.storage()))\n",
    "      # print(\"The size in bytes of data_y\", sys.getsizeof(data_y.storage()))\n",
    "\n",
    "      # normalise y labels\n",
    "      data_y = normalise_data(data_y, norm_factors)\n",
    "\n",
    "      num_batches = len(data_x) // batch_size\n",
    "      total_batches += num_batches\n",
    "      rand_idx = torch.randperm(data_x.shape[0])\n",
    "      avg_loss = 0\n",
    "\n",
    "      print(f\"Starting slice {slice_num + 1} / {len(data_inds)}. There will be {num_batches} batches. \", end=\"\", flush=True)\n",
    "\n",
    "      # iterate through each batch for this slice of the dataset\n",
    "      for n in range(num_batches):\n",
    "\n",
    "        batch_x = data_x[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "        batch_y = data_y[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "        # go to cuda\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # use the model for a prediction and calculate loss\n",
    "        net_y = net.board_cnn(batch_x)\n",
    "        loss = lossfcn(net_y.squeeze(1), batch_y)\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        # if n % 500 == 0:\n",
    "        #   print(f\"Loss is {(avg_loss / (n + 1)) * 1000:.3f}, epoch {i + 1}, batch {n + 1} / {num_batches}\")\n",
    "\n",
    "      # this dataset slice is finished\n",
    "      epoch_loss += avg_loss\n",
    "      avg_loss = avg_loss / num_batches\n",
    "      avg_loss = avg_loss ** 0.5 * norm_factors[0] * norm_factors[2] # try to scale to original units\n",
    "      print(f\"Loss is {avg_loss:.3f}, during epoch {i + 1}, slice {slice_num + 1} / {len(data_inds)}\", flush=True)\n",
    "  \n",
    "    # this epoch is finished\n",
    "    epoch_loss = epoch_loss / total_batches\n",
    "    epoch_loss = epoch_loss ** 0.5 * norm_factors[0] * norm_factors[2] # try to scale to original units\n",
    "    print(f\"Epoch {i + 1} has finished after {total_batches} batches. Overall average loss = {epoch_loss:.3f}\", flush=True)\n",
    "\n",
    "  # finally, return the network that we have trained\n",
    "  return net\n",
    "\n",
    "do_train_procedure = False\n",
    "\n",
    "if do_train_procedure:\n",
    "\n",
    "  net = ChessNet(19)\n",
    "\n",
    "  device = \"cuda\"\n",
    "  epochs = 10\n",
    "  data_inds = list(range(1, 11))\n",
    "  lr = 1e-7\n",
    "\n",
    "  trained_net = train_procedure(\n",
    "    net=net,\n",
    "    dataname=\"datasetv1\",\n",
    "    dataloader=ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=1),\n",
    "    data_inds=list(range(1, 11)),\n",
    "    norm_factors=[23.927, -0.240, 0.355], # [max, mean, std]\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    device=device    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training = False\n",
    "\n",
    "if test_training:\n",
    "\n",
    "  # net = BoardCNN()\n",
    "  net = ChessNet(19)\n",
    "\n",
    "  device = \"cuda\"\n",
    "  epochs = 10\n",
    "  lr = 1e-7\n",
    "\n",
    "  # # normalise the evaluations\n",
    "  # print(torch.min(dataset.evals))\n",
    "  # print(torch.max(dataset.evals))\n",
    "  # dataset.evals /= torch.max(dataset.evals)\n",
    "  print(torch.min(dataset.evals))\n",
    "  print(torch.max(dataset.evals))\n",
    "\n",
    "  trained_net = train(net, dataset.boards, dataset.evals, device=device, epochs=epochs, lr=lr)\n",
    "  modelsaver = ModelSaver(\"/home/luke/chess/python/models/\")\n",
    "  modelsaver.save(\"eval_model\", trained_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /home/luke/chess/python/models/01-11-24/run_12-19_A1/network_001.lz4 with pickle ... finished\n",
      "Loading file /home/luke/chess/python/datasets/datasetv3/data_torch_065.lz4 with pickle ... finished\n",
      "The average difference from 1000 samples is u=3.416 s=3.866, stockfish average difference is u=2.132 s=2.764\n"
     ]
    }
   ],
   "source": [
    "def torch_to_board_vec(tensor):\n",
    "  \"\"\"\n",
    "  Convert a torch board vector into a cpp board vector\n",
    "  \"\"\"\n",
    "\n",
    "  boardvec = bf.BoardVectors()\n",
    "\n",
    "  boardvec.wP = list(tensor[0].reshape(64))\n",
    "  boardvec.wN = list(tensor[1].reshape(64))\n",
    "  boardvec.wB = list(tensor[2].reshape(64))\n",
    "  boardvec.wR = list(tensor[3].reshape(64))\n",
    "  boardvec.wQ = list(tensor[4].reshape(64))\n",
    "  boardvec.wK = list(tensor[5].reshape(64))\n",
    "  boardvec.bP = list(tensor[6].reshape(64))\n",
    "  boardvec.bN = list(tensor[7].reshape(64))\n",
    "  boardvec.bB = list(tensor[8].reshape(64))\n",
    "  boardvec.bR = list(tensor[9].reshape(64))\n",
    "  boardvec.bQ = list(tensor[10].reshape(64))\n",
    "  boardvec.bK = list(tensor[11].reshape(64))\n",
    "  boardvec.wKS = list(tensor[12].reshape(64))\n",
    "  boardvec.wQS = list(tensor[13].reshape(64))\n",
    "  boardvec.bKS = list(tensor[14].reshape(64))\n",
    "  boardvec.bQS = list(tensor[15].reshape(64))\n",
    "  boardvec.colour = list(tensor[16].reshape(64))\n",
    "\n",
    "  return boardvec\n",
    "\n",
    "loadexisting = True\n",
    "\n",
    "if loadexisting:\n",
    "\n",
    "  if False:\n",
    "    modelloader = ModelSaver(\"/home/luke/chess/python/models/\")\n",
    "    trained_net = modelloader.load(\"chessnet_model\", id=None)\n",
    "  else:\n",
    "    group = \"01-11-24\"\n",
    "    run = \"run_12-19_A1\"\n",
    "    modelloader = ModelSaver(f\"/home/luke/chess/python/models/{group}/{run}\")\n",
    "    trained_net = modelloader.load(\"network\", id=None)\n",
    "  \n",
    "  dataset_name = \"datasetv3\"\n",
    "  dataset_ind = 65\n",
    "  dataloader = ModelSaver(f\"/home/luke/chess/python/datasets/{dataset_name}\")\n",
    "  boards, evals, sq_evals = dataloader.load(\"data_torch\", id=dataset_ind)\n",
    "\n",
    "  device = \"cpu\"\n",
    "  trained_net.board_cnn.to(device)\n",
    "  boards = boards.to(device)\n",
    "  evals = evals.to(device)\n",
    "  sq_evals = sq_evals.to(device)\n",
    "\n",
    "  trained_net.board_cnn.eval()\n",
    "\n",
    "rand = False\n",
    "inds = list(range(len(evals)))\n",
    "if rand:\n",
    "  random.shuffle(inds)\n",
    "\n",
    "my_diff_vec = []\n",
    "sf_diff_vec = []\n",
    "\n",
    "avg_diff_sf = 0\n",
    "avg_diff_my = 0\n",
    "n = 1000\n",
    "inds = inds[:n]\n",
    "for i in inds:\n",
    "\n",
    "  # # evaluation comparison\n",
    "  # sf_eval = dataset.positions[i].eval\n",
    "  # net_eval = trained_net.board_cnn(dataset.boards[i].to(device).unsqueeze(dim=0))\n",
    "  # net_eval = net_eval.to(\"cpu\").item()\n",
    "  # if dataset.use_eval_normalisation:\n",
    "  #   net_eval = dataset.denomormalise_evaluation(value=net_eval)\n",
    "  # diff = abs(sf_eval*1e-3 - net_eval)\n",
    "  # avg_diff += diff\n",
    "  # if n <= 20:\n",
    "  #   print(f\"sf_eval = {sf_eval * 1e-3:.3f}, net_eval = {net_eval:.3f}, difference is {diff:.3f}\")\n",
    "\n",
    "  # board piece rating comparison\n",
    "  net_eval = (trained_net.board_cnn(boards[i].unsqueeze(dim=0))).to(\"cpu\")\n",
    "  net_eval = denormalise_data(net_eval, factors=[7, 0, 2.159])\n",
    "\n",
    "  this_board_vec = boards[i].to(\"cpu\")\n",
    "  this_sf_eval = evals[i].to(\"cpu\") * 10\n",
    "  this_sq_evals = sq_evals[i].to(\"cpu\")\n",
    "\n",
    "  # board_vec = bf.FEN_to_board_vectors_with_eval(dataset.positions[i].fen_string)\n",
    "  # board_vec = torch.tensor(board_vec.sq_evals, dtype=torch.float) * 1e-3\n",
    "  \n",
    "  net_overall = torch.sum(net_eval)\n",
    "  true_overall = torch.sum(this_sq_evals)\n",
    "\n",
    "  net_print = torch.zeros((8, 8))\n",
    "  true_print = torch.zeros((8, 8))\n",
    "  \n",
    "  torch.round(net_eval.reshape(8,8).detach(), decimals=2, out=net_print)\n",
    "  torch.round(this_sq_evals.reshape(8,8).detach(), decimals=2, out=true_print)\n",
    "\n",
    "  sf_diff = this_sf_eval - net_overall\n",
    "  my_diff = true_overall - net_overall\n",
    "\n",
    "  my_diff_vec.append(my_diff.detach().item())\n",
    "  sf_diff_vec.append(sf_diff.detach().item())\n",
    "\n",
    "  avg_diff_sf += abs(sf_diff)\n",
    "  avg_diff_my += abs(my_diff)\n",
    "  \n",
    "  if n <= 50:\n",
    "    print(f\"Case {i + 1} / {n}.\", end=\" \")\n",
    "    if n < 6:\n",
    "      print(\"Board:\")\n",
    "      bf.print_board_vectors(torch_to_board_vec(this_board_vec))\n",
    "      # bf.print_FEN_board(dataset.positions[i].fen_string)\n",
    "      print(\"Net eval was\\n\", net_print)\n",
    "      print(\"Ground truth was\\n\", true_print)\n",
    "    print(f\"sf_eval = {this_sf_eval:.3f}, True evaluation = {true_overall:.3f}, net eval = {net_overall:.3f}, difference = {true_overall - net_overall:.3f}\")\n",
    "\n",
    "diff_sf = np.array(sf_diff_vec)\n",
    "mean_sf_diff = np.mean(np.abs(diff_sf))\n",
    "std_sf_diff = np.std(diff_sf)\n",
    "\n",
    "diff_my = np.array(my_diff_vec)\n",
    "mean_my_diff = np.mean(np.abs(diff_my))\n",
    "std_my_diff = np.std(diff_my)\n",
    "\n",
    "print(f\"The average difference from {n} samples is u={mean_my_diff:.3f} s={std_my_diff:.3f}, stockfish average difference is u={mean_sf_diff:.3f} s={std_sf_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].hist(diff_sf, bins=40, range=(-10, 10))\n",
    "axs[1].hist(diff_my, bins=40, range=(-10, 10))\n",
    "axs[0].set_title(\"Stockfish evaluation difference\")\n",
    "axs[1].set_title(\"My evaluation function difference\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move: e1g1, eval = 80\n",
      "Move: c1e3, eval = 71\n",
      "Move: h2h4, eval = 70\n",
      "Move: a4a5, eval = 61\n",
      "Move: c1g5, eval = 59\n",
      "Move: e4e5, eval = 59\n",
      "Move: c1f4, eval = 59\n",
      "Move: a1b1, eval = 55\n",
      "Move: d1c2, eval = 36\n",
      "Move: c4b3, eval = 31\n",
      "Move: h2h3, eval = 29\n",
      "Move: c1d2, eval = 26\n",
      "Move: e2g3, eval = 18\n",
      "Move: a1a2, eval = 18\n",
      "Move: a1a3, eval = 14\n",
      "Move: c4a2, eval = 10\n",
      "Move: b2b3, eval = 10\n",
      "Move: c4b5, eval = 9\n",
      "Move: e1f2, eval = 5\n",
      "Move: d1d3, eval = 5\n",
      "Move: b2b4, eval = 3\n",
      "Move: d1b3, eval = 2\n",
      "Move: e2f4, eval = -1\n",
      "Move: c3b5, eval = -1\n",
      "Move: d1d2, eval = -1\n",
      "Move: c4d3, eval = -10\n",
      "Move: g2g4, eval = -19\n",
      "Move: g2g3, eval = -24\n",
      "Move: h1f1, eval = -32\n",
      "Move: c3a2, eval = -38\n",
      "Move: e1f1, eval = -39\n",
      "Move: c3b1, eval = -55\n",
      "Move: e2g1, eval = -56\n",
      "Move: d4d5, eval = -59\n",
      "Move: h1g1, eval = -65\n",
      "Move: e1d2, eval = -169\n",
      "Move: c4d5, eval = -234\n",
      "Move: f3f4, eval = -252\n",
      "Move: c3d5, eval = -261\n",
      "Move: c4f7, eval = -335\n",
      "Move: c4e6, eval = -366\n",
      "Move: c1h6, eval = -391\n",
      "Move: c4a6, eval = -507\n"
     ]
    }
   ],
   "source": [
    "torch.max(evals)\n",
    "x = 13\n",
    "for i in range(len(dataset.positions[x].move_vector)):\n",
    "  print(f\"Move: {dataset.positions[x].move_vector[i].move_letters}, eval = {dataset.positions[x].move_vector[i].eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: Total time 10.6s, so 10.566 ms per evaluation\n",
      "Handcrafted: Total time 0.5s, so 0.478 ms per evaluation\n"
     ]
    }
   ],
   "source": [
    "time_net = True\n",
    "\n",
    "if time_net:\n",
    "\n",
    "  timedevice = \"cuda\"\n",
    "  trained_net.board_cnn.eval()\n",
    "  trained_net.board_cnn.to(timedevice)\n",
    "  num = 1000\n",
    "  j = 0\n",
    "\n",
    "  t1 = time.process_time()\n",
    "  for i in range(num):\n",
    "    trained_net.board_cnn(dataset.boards[j].to(timedevice).unsqueeze(dim=0))\n",
    "    j += 1\n",
    "    if j >= len(dataset.boards):\n",
    "      j = 0\n",
    "  t2 = time.process_time()\n",
    "\n",
    "  print(f\"Network: Total time {t2 - t1:.1f}s, so {((t2 - t1) / num) * 1e3:.3f} ms per evaluation\")\n",
    "\n",
    "  t1 = time.process_time()\n",
    "  for i in range(num):\n",
    "    bf.generate_moves_FEN(dataset.positions[j].fen_string)\n",
    "    j += 1\n",
    "    if j >= len(dataset.boards):\n",
    "      j = 0\n",
    "  t2 = time.process_time()\n",
    "\n",
    "  print(f\"Handcrafted: Total time {t2 - t1:.1f}s, so {((t2 - t1) / num) * 1e3:.3f} ms per evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_training = False\n",
    "\n",
    "if extend_training:\n",
    "\n",
    "  more_epochs = 10\n",
    "  new_lr = 1e-8\n",
    "  trained_net = train(trained_net, dataset.boards, dataset.evals, device=device, epochs=more_epochs, lr=new_lr)\n",
    "  modelsaver = ModelSaver(\"/home/luke/chess/python/models/\")\n",
    "  modelsaver.save(\"eval_model\", trained_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
