{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.board_module as bf\n",
    "import modules.tree_module as tf\n",
    "import modules.stockfish_module as sf\n",
    "from ModelSaver import ModelSaver\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from math import floor, ceil\n",
    "import pandas as pd\n",
    "\n",
    "from train_nn_evaluator import Trainer, EvalDataset, ChessNet, ResNet\n",
    "from assemble_data import Move, Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /home/luke/chess/python/gamedata/samples/random_n=4096_sample_354.lz4 with pickle ... finished\n",
      "EvalDataset(): 1 files loaded 0.23 seconds\n"
     ]
    }
   ],
   "source": [
    "# load in the entire dataset\n",
    "num_rand = 4096\n",
    "datapath = \"/home/luke/chess/python/gamedata/samples\"\n",
    "eval_file_template = \"random_n={0}_sample\"\n",
    "inds = list(range(1))\n",
    "log_level = 1\n",
    "dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                      indexes=inds, log_level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = False\n",
    "\n",
    "if process_data:\n",
    "\n",
    "  print(f\"Total number of positions = {len(dataset)}\")\n",
    "  num_duplicates = dataset.check_duplicates()\n",
    "  num_mates = dataset.check_mate_positions()\n",
    "  print(f\"Proportion of duplicates = {(num_duplicates / len(dataset))*100:.1f} %\")\n",
    "  print(f\"Proportion of mate positions = {(num_mates / len(dataset))*100:.1f} %\")\n",
    "\n",
    "  # prepare the dataset\n",
    "  print(\"REMOVING MATES AND DUPLICATES\")\n",
    "  num_duplicates = dataset.check_duplicates(remove=True)\n",
    "  num_mates = dataset.check_mate_positions(remove=True)\n",
    "  dataset.board_dtype = torch.float\n",
    "  dataset.to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savenew = False\n",
    "\n",
    "if savenew:\n",
    "\n",
    "  dataset_name = \"datasetv2\"\n",
    "  file_name = \"data\"\n",
    "  ind_per = 2               # indexes per slice of the dataset\n",
    "  total_index = 140         # largest index number of gamedata/samples file\n",
    "  prevent_duplicates = True # prevent duplicates across the entire set, not just in each slice\n",
    "  savetorchonly = False     # save only the finalised torch tensors\n",
    "  savetorchtoo = True       # save also a torch version of the dataset\n",
    "  log_level = 1             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "\n",
    "  num_sets = total_index // ind_per\n",
    "  if prevent_duplicates: seen_values = set()\n",
    "\n",
    "  datasaver = ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  datasaver.new_folder(dataset_name)\n",
    "\n",
    "  for ind in range(num_sets):\n",
    "\n",
    "    print(\"Loading set\", ind + 1, \"/\", num_sets)\n",
    "    indexes = list(range(ind * ind_per + 1, ((ind + 1) * ind_per) + 1))\n",
    "    dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                          indexes=indexes, log_level=log_level)\n",
    "    if prevent_duplicates: dataset.seen_values = seen_values\n",
    "    num_duplicates = dataset.check_duplicates(remove=True, wipe_seen=not prevent_duplicates)\n",
    "    num_mates = dataset.check_mate_positions(remove=True)\n",
    "    dataset.board_dtype = torch.float\n",
    "    dataset.to_torch()\n",
    "    if savetorchonly or savetorchtoo:\n",
    "      if dataset.eval_squares:\n",
    "        datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals, dataset.square_evals])\n",
    "      else:\n",
    "        datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals])\n",
    "    elif not savetorchonly:\n",
    "      datasaver.save(file_name, dataset)\n",
    "    if prevent_duplicates: seen_values = dataset.seen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savenew_randomised = False\n",
    "\n",
    "if savenew_randomised:\n",
    "\n",
    "  dataset_name = \"datasetv9\"\n",
    "  file_name = \"data\"\n",
    "  max_files = None          # maximum number of files to generate, default=None\n",
    "  num_per = 200_000         # number of lines per saved file\n",
    "  total_index = 354         # largest index number of gamedata/samples file\n",
    "  prevent_duplicates = True # prevent duplicates across the entire set, not just in each slice\n",
    "  log_level = 1             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "  test_files = 5            # number of files reserved for tests only\n",
    "\n",
    "  # variables for distribution characterisation\n",
    "  clip_checkmate = 15       # only for distribution analysis - does NOT apply to dataset itself\n",
    "  num_bins = 100            # number of histogram bins to save data for\n",
    "\n",
    "  datasaver = ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  datasaver.new_folder(dataset_name)\n",
    "\n",
    "  start_index = 1\n",
    "  indexes = list(range(start_index, total_index + 1))\n",
    "  dataset = EvalDataset(datapath, eval_file_template.format(num_rand),\n",
    "                          indexes=indexes, log_level=log_level)\n",
    "  \n",
    "  # ensure key settings are correct\n",
    "  dataset.use_eval_normalisation = False\n",
    "  dataset.save_sq_eval = True\n",
    "  dataset.use_parent_positions = True\n",
    "\n",
    "  # remove any duplicates and mate positions\n",
    "  num_duplicates = dataset.check_duplicates(remove=True)\n",
    "  num_mates = dataset.check_mate_positions(remove=True)\n",
    "  # dataset.to_torch() # old, convert ALL to torch\n",
    "\n",
    "  # now randomise a selection of the indexes\n",
    "  num_pos = len(dataset.positions)\n",
    "  num_boards = dataset.count_all_positions()\n",
    "\n",
    "  test_num = test_files * num_per\n",
    "  train_indexes = list(range(num_boards - test_num))\n",
    "  test_indexes = list(range(num_boards - test_num, num_boards))\n",
    "  random.shuffle(train_indexes)\n",
    "  random.shuffle(test_indexes)\n",
    "\n",
    "  num_files = num_boards // num_per\n",
    "  num_lost = num_boards - num_files * num_per\n",
    "  train_indexes = train_indexes[:-num_lost]\n",
    "\n",
    "  # now combine into our finalised index list\n",
    "  indexes = train_indexes + test_indexes\n",
    "\n",
    "  ind = 0\n",
    "\n",
    "  if max_files is not None:\n",
    "    if num_files > max_files:\n",
    "      print(f\"The number of files is limited from {num_files} to {max_files}\")\n",
    "      num_files = max_files\n",
    "\n",
    "  print(\"num_files is\", num_files)\n",
    "  print(\"num_boards is\", num_boards)\n",
    "  print(\"num_lost is\", num_lost)\n",
    "  print(f\"length train_indexes = {len(train_indexes)}, so {len(train_indexes) / num_per} files\")\n",
    "  print(f\"length test_indexes = {len(test_indexes)}, so {len(test_indexes) / num_per} files\")\n",
    "  print(f\"length indexes = {len(indexes)}, so {len(indexes) / num_per} files\")\n",
    "\n",
    "  # prepare to save distribution data\n",
    "  sf_file_means = []\n",
    "  sf_file_var = []\n",
    "  sf_file_max = []\n",
    "  my_file_means_raw = []\n",
    "  my_file_var_raw = []\n",
    "  my_file_max_raw = []\n",
    "  my_file_means_sum = []\n",
    "  my_file_var_sum = []\n",
    "  my_file_max_sum = []\n",
    "  both_file_means = []\n",
    "  both_file_var = []\n",
    "  both_file_max = []\n",
    "  sf_bins = np.linspace(-clip_checkmate, clip_checkmate, num_bins)\n",
    "  my_bins_raw = np.linspace(-clip_checkmate, clip_checkmate, num_bins)\n",
    "  my_bins_sum = np.linspace(-clip_checkmate, clip_checkmate, num_bins)\n",
    "  sf_bin_counts = np.zeros(num_bins - 1)\n",
    "  my_raw_bin_counts = np.zeros(num_bins - 1)\n",
    "  my_sum_bin_counts = np.zeros(num_bins - 1)\n",
    "  \n",
    "  for n in range(num_files):\n",
    "\n",
    "    # random selection of indexes for the current file\n",
    "    these_indexes = indexes[n * num_per : (n + 1) * num_per]\n",
    "    \n",
    "    # convert only the selected indexes to torch\n",
    "    dataset.to_torch(indexes_only=these_indexes)\n",
    "\n",
    "    # save the converted tensors\n",
    "    datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals, dataset.square_evals])\n",
    "\n",
    "    # now prepare to analyse the distribution\n",
    "    data_sf = dataset.evals\n",
    "    data_my_raw = dataset.square_evals\n",
    "    data_my_sum = torch.sum(dataset.square_evals, dim=1)\n",
    "    data_both = torch.cat((dataset.evals.unsqueeze(1), dataset.square_evals), dim=1)\n",
    "\n",
    "    # calculate max, and then clip large values to prevent distribution skew\n",
    "    sf_file_max.append(torch.max(torch.abs(data_sf)).item())\n",
    "    my_file_max_raw.append(torch.max(torch.abs(data_my_raw)).item())\n",
    "    my_file_max_sum.append(torch.max(torch.abs(data_my_sum)).item())\n",
    "    both_file_max.append(torch.max(torch.abs(data_both)).item())\n",
    "    data_sf = torch.clip(data_sf, -clip_checkmate, clip_checkmate)\n",
    "    data_my_raw = torch.clip(data_my_raw, -clip_checkmate, clip_checkmate)\n",
    "    data_my_sum = torch.clip(data_my_sum, -clip_checkmate, clip_checkmate)\n",
    "    data_both = torch.clip(data_both, -clip_checkmate, clip_checkmate)\n",
    "\n",
    "    # calculate mean, variance, max\n",
    "    sf_file_means.append(torch.mean(data_sf).item())\n",
    "    sf_file_var.append(torch.var(data_sf).item())\n",
    "    my_file_means_raw.append(torch.mean(data_my_raw).item())\n",
    "    my_file_var_raw.append(torch.var(data_my_raw).item())\n",
    "    my_file_means_sum.append(torch.mean(data_my_sum).item())\n",
    "    my_file_var_sum.append(torch.var(data_my_sum).item())\n",
    "    both_file_means.append(torch.mean(data_both).item())\n",
    "    both_file_var.append(torch.var(data_both).item())\n",
    "\n",
    "    # calculate distribution histogram\n",
    "    sf_counts, _ = np.histogram(data_sf.detach().numpy(), bins=sf_bins)\n",
    "    my_raw_counts, _ = np.histogram(data_my_raw.detach().numpy(), bins=sf_bins)\n",
    "    my_sum_counts, _ = np.histogram(data_my_sum.detach().numpy(), bins=sf_bins)\n",
    "    sf_bin_counts += sf_counts\n",
    "    my_raw_bin_counts += my_raw_counts\n",
    "    my_sum_bin_counts += my_sum_counts\n",
    "\n",
    "  # finish by calculating distribution data over the new dataset\n",
    "  my_means_raw = np.array(my_file_means_raw)\n",
    "  my_overall_mean_raw = np.mean(my_means_raw)\n",
    "  my_overal_std_raw = np.sqrt(np.mean(my_file_var_raw) + np.mean(np.power(my_means_raw - my_overall_mean_raw, 2)))\n",
    "  my_max_raw = np.max(my_file_max_raw)\n",
    "  my_means_sum = np.array(my_file_means_sum)\n",
    "  my_overall_mean_sum = np.mean(my_means_sum)\n",
    "  my_overal_std_sum = np.sqrt(np.mean(my_file_var_sum) + np.mean(np.power(my_means_sum - my_overall_mean_sum, 2)))\n",
    "  my_max_sum = np.max(my_file_max_sum)\n",
    "  sf_means = np.array(sf_file_means)\n",
    "  sf_overall_mean = np.mean(sf_means)\n",
    "  sf_overal_std = np.sqrt(np.mean(sf_file_var) + np.mean(np.power(sf_means - sf_overall_mean, 2)))\n",
    "  sf_max = np.max(sf_file_max)\n",
    "  both_means = np.array(both_file_means)\n",
    "  both_overall_mean = np.mean(both_means)\n",
    "  both_overal_std = np.sqrt(np.mean(both_file_var) + np.mean(np.power(both_means - both_overall_mean, 2)))\n",
    "  both_max = np.max(both_file_max)\n",
    "\n",
    "  summary_str = \"\"\"\"\"\"\n",
    "  summary_str += f\"Dataset name: {dataset_name}\\n\"\n",
    "  summary_str += f\"Number of loaded files: {total_index}\\n\"\n",
    "  summary_str += f\"Number of core positions: {num_pos}\\n\"\n",
    "  summary_str += f\"Number of total boards: {num_boards}\\n\"\n",
    "  summary_str += f\"Number of created dataset files: {num_files}\\n\"\n",
    "  summary_str += \"\\nDistribution data:\\n\"\n",
    "  summary_str += f\"Stockfish (mean, std, max) = ({sf_overall_mean:.3f}, {sf_overal_std:.3f}, {sf_max:.3f})\\n\"\n",
    "  summary_str += f\"My evals per square (mean, std, max) = ({my_overall_mean_raw:.3f}, {my_overal_std_raw:.3f}, {my_max_raw:.3f})\\n\"\n",
    "  summary_str += f\"My evals per board (mean, std, max) = ({my_overall_mean_sum:.3f}, {my_overal_std_sum:.3f}, {my_max_sum:.3f})\\n\"\n",
    "  summary_str += f\"Both (mean, std, max) = ({both_overall_mean:.3f}, {both_overal_std:.3f}, {both_max:.3f})\\n\"\n",
    "\n",
    "  # save the summary string and distribution data\n",
    "  datasaver.save(\"summary\", txtonly=True, txtstr=summary_str)\n",
    "  datasaver.save(\"distribution\", [\n",
    "    (sf_bin_counts, my_raw_bin_counts, my_sum_bin_counts), \n",
    "    (sf_bins, my_bins_raw, my_bins_sum),\n",
    "    ((sf_overall_mean, sf_overal_std, sf_max),\n",
    "    (my_overall_mean_raw, my_overal_std_raw, my_max_raw),\n",
    "    (both_overall_mean, both_overal_std, both_max)),\n",
    "  ], suffix_numbering=False)\n",
    "\n",
    "  print(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savenew_randomised:\n",
    "\n",
    "  fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "  axs[0].bar(sf_bins[:-1], sf_bin_counts, width=np.diff(sf_bins), align=\"edge\")\n",
    "  axs[1].bar(my_bins_raw[:-1], my_raw_bin_counts, width=np.diff(my_bins_raw), align=\"edge\")\n",
    "  axs[2].bar(my_bins_sum[:-1], my_sum_bin_counts, width=np.diff(my_bins_sum), align=\"edge\")\n",
    "\n",
    "  fig.suptitle(f\"Dataset: {dataset_name}, num_boards = {int(num_files * num_per / 1e3)}k\")\n",
    "  axs[0].set_title(f\"stockfish evaluations\")\n",
    "  axs[1].set_title(f\"per square piece evaluations\")\n",
    "  axs[2].set_title(f\"my evaluations\")\n",
    "\n",
    "  for a in axs:\n",
    "    a.set_ylabel(\"Frequency\")\n",
    "  axs[2].set_xlabel(\"Evaluation score / pawns\")\n",
    "\n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /home/luke/chess//python/datasets/datasetv8/distribution.lz4 with pickle ... finished\n",
      "Loading file /home/luke/chess//python/datasets/datasetv8/data_torch_001.lz4 with pickle ... finished\n",
      "The number of samples was 200000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datestr = \"%d-%m-%y_%H-%M\" # all date inputs must follow this format\n",
    "timestamp = datetime.now().strftime(datestr)\n",
    "run_name = f\"run_{timestamp[-5:]}_A{1}\"\n",
    "group_name = timestamp[:8]\n",
    "\n",
    "train_num = 160\n",
    "test_num = 7\n",
    "\n",
    "# saving/loading information\n",
    "data_dict = {\n",
    "  \"path\" : \"/home/luke/chess\",\n",
    "  \"loadpath\" : \"/python/datasets\",\n",
    "  \"loadfolder\" : \"datasetv8\",\n",
    "  \"loadname\" : \"data_torch\",\n",
    "  \"savepath\" : \"/python/models\",\n",
    "  \"savefolder\" : f\"{group_name}/{run_name}\",\n",
    "  \"savename\" : \"network\",\n",
    "  \"train_inds\" : list(range(1, train_num + 1)),\n",
    "  \"test_inds\" : list(range(train_num + 1, \n",
    "                           train_num + test_num + 1)),\n",
    "  \"sample_method\" : \"weighted\",\n",
    "  \"load_log_level\" : 1,\n",
    "  \"save_log_level\" : 1,\n",
    "}\n",
    "\n",
    "# create the trainer object\n",
    "trainer = Trainer(data_dict)\n",
    "# trainer.norm_factors = [10, 0, 4]\n",
    "trainer.batch_limit = None\n",
    "trainer.params.use_combined_loss = False\n",
    "trainer.params.use_sf_eval = True\n",
    "\n",
    "# # load in the dataset distribution data\n",
    "# [sf_bin_counts, my_raw_bin_counts, my_sum_bin_counts] = trainer.dataloader.load(\"distribution\", suffix_numbering=False)\n",
    "\n",
    "batch_size = 64\n",
    "total_batches = 0\n",
    "device = \"cpu\"\n",
    "\n",
    "# load the dataset in a series of slices (with randomised order)\n",
    "train_load_indexes = trainer.data_dict['train_inds'][:]\n",
    "random.shuffle(train_load_indexes)\n",
    "\n",
    "train_load_indexes = [1]\n",
    "\n",
    "num_batches = 200_000 // batch_size \n",
    "if trainer.batch_limit is not None: num_batches = trainer.batch_limit\n",
    "samples = torch.zeros(batch_size * num_batches * len(train_load_indexes))\n",
    "w_samples = torch.zeros(batch_size * num_batches * len(train_load_indexes))\n",
    "sample_ind = 0\n",
    "w_sample_ind = 0\n",
    "\n",
    "for slice_num, j in enumerate(train_load_indexes):\n",
    "\n",
    "  # load this segment of the dataset\n",
    "  data_x, data_y, sf_evals, sq_evals = trainer.prepare_data(trainer.data_dict['loadname'], j, return_dataset=True)\n",
    "\n",
    "  num_batches = len(data_x) // batch_size\n",
    "  if num_batches == 0:\n",
    "    raise RuntimeError(\"Trainer.train() found num_batches = 0\")\n",
    "  \n",
    "  # useful for debugging and testing\n",
    "  if trainer.batch_limit is not None:\n",
    "    num_batches = trainer.batch_limit\n",
    "\n",
    "  total_batches += num_batches\n",
    "  rand_idx = torch.randperm(data_x.shape[0])\n",
    "  avg_loss = 0\n",
    "\n",
    "  t1 = time.time()\n",
    "\n",
    "  trainer.weighted_sample_num_combined_bins = 20\n",
    "  sampler = trainer.create_weighted_sampler(sf_evals)\n",
    "\n",
    "  # iterate through each batch for this slice of the dataset\n",
    "  for n in range(num_batches):\n",
    "\n",
    "    # get a normal sample\n",
    "    batch_x = data_x[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "    batch_y = data_y[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "    samples[sample_ind : sample_ind + batch_size] = batch_y\n",
    "    sample_ind += batch_size\n",
    "\n",
    "    # now get a weighted sample\n",
    "    # w_x = data_x[w_sample_indicies[n * batch_size : (n+1) * batch_size]]\n",
    "    # w_y = data_y[w_sample_indicies[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "    w_sample_indicies = list(sampler)\n",
    "    w_x = data_x[w_sample_indicies]\n",
    "    w_y = data_y[w_sample_indicies]\n",
    "\n",
    "    w_samples[w_sample_ind : w_sample_ind + batch_size] = w_y\n",
    "    w_sample_ind += batch_size\n",
    "\n",
    "    # # go to device (small memory footprint, slightly slower)\n",
    "    # batch_x = batch_x.to(device)\n",
    "    # batch_y = batch_y.to(device)\n",
    "\n",
    "print(f\"The number of samples was {sample_ind}\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].hist(samples.detach().numpy(), bins=50)\n",
    "axs[1].hist(w_samples.detach().numpy(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].hist(samples.detach().numpy(), bins=50)\n",
    "axs[1].hist(w_samples.detach().numpy(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kaggle = False\n",
    "convert_kaggle = False\n",
    "save_kaggle = False\n",
    "new_kaggle_set = False\n",
    "\n",
    "if load_kaggle:\n",
    "\n",
    "  datapath = \"/home/luke/chess/python/gamedata/kaggle\"\n",
    "  file_name = \"chessData.csv\"\n",
    "\n",
    "  df = pd.read_csv(datapath + \"/\" + file_name)\n",
    "\n",
    "if convert_kaggle:\n",
    "\n",
    "  mate_value = 15 * 100\n",
    "  positions = []\n",
    "  print(f\"The number of positions is {len(df['FEN'])}\")\n",
    "\n",
    "  # add all of the positions into the dataset\n",
    "  for i in range(len(df[\"FEN\"])):\n",
    "\n",
    "    if i % 100_000 == 0: print(i / 1_000_000, end=\" \")\n",
    "    if i % 1_000_000 == 0: print()\n",
    "\n",
    "    eval = df[\"Evaluation\"][i]\n",
    "    if eval.startswith(\"#+\"):\n",
    "      eval = mate_value\n",
    "    elif eval.startswith(\"#-\"):\n",
    "      eval = -mate_value\n",
    "\n",
    "    eval = int(eval)\n",
    "\n",
    "    new_pos = Position(df[\"FEN\"][i], eval, None)\n",
    "    positions.append(new_pos)\n",
    "\n",
    "if save_kaggle:\n",
    "\n",
    "  tempsaver = ModelSaver(datapath)\n",
    "  tempsaver.save(\"positions\", positions)\n",
    "\n",
    "if new_kaggle_set:\n",
    "\n",
    "  dataset_name = \"dataset_kaggle_2\"\n",
    "  file_name = \"data\"\n",
    "  max_files = None          # maximum number of files to generate, default=None\n",
    "  num_per = 200_000         # number of lines per saved file\n",
    "  prevent_duplicates = True # prevent duplicates across the entire set, not just in each slice\n",
    "  log_level = 1             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "\n",
    "  datasaver = ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  datasaver.new_folder(dataset_name)\n",
    "\n",
    "  dataset = EvalDataset(\"\", \"\", auto_load=False, log_level=log_level)\n",
    "  \n",
    "  # ensure key settings are correct\n",
    "  dataset.use_all_moves = False\n",
    "  dataset.use_eval_normalisation = False\n",
    "  dataset.save_sq_eval = True\n",
    "\n",
    "  # add in the kaggle positions\n",
    "  dataset.positions = positions\n",
    "\n",
    "  # remove any duplicates and mate positions\n",
    "  num_duplicates = dataset.check_duplicates(remove=True)\n",
    "  num_mates = dataset.check_mate_positions(remove=True)\n",
    "  # dataset.to_torch() # old, convert ALL to torch\n",
    "\n",
    "  # now randomise a selection of the indexes\n",
    "  num_boards = dataset.count_all_positions()\n",
    "  indexes = list(range(num_boards))\n",
    "  random.shuffle(indexes)\n",
    "\n",
    "  num_files = num_boards // num_per\n",
    "  ind = 0\n",
    "\n",
    "  if max_files is not None:\n",
    "    if num_files > max_files:\n",
    "      print(f\"The number of files is limited from {num_files} to {max_files}\")\n",
    "      num_files = max_files\n",
    "\n",
    "  print(\"num_files is\", num_files)\n",
    "  print(\"num_boards is\", num_boards)\n",
    "  \n",
    "  for n in range(num_files):\n",
    "\n",
    "    # random selection of indexes for the current file\n",
    "    these_indexes = indexes[n * num_per : (n + 1) * num_per]\n",
    "    \n",
    "    # convert only the selected indexes to torch\n",
    "    dataset.to_torch(indexes_only=these_indexes)\n",
    "\n",
    "    # save the converted tensors\n",
    "    datasaver.save(file_name + \"_torch\", [dataset.boards, dataset.evals, dataset.square_evals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterise_dataset = False\n",
    "\n",
    "if characterise_dataset:\n",
    "\n",
    "  dataset_name = \"datasetv7\"\n",
    "  file_name = \"data_torch\"\n",
    "  total_index = 141         # largest index number of gamedata/samples file\n",
    "  log_level = 0             # log level during the dataset generation (0=bare minimum, 1=normal)\n",
    "  clip_checkmate = 15       # clip largest eval to this value (checkmate essentially)\n",
    "\n",
    "  dataloader = ModelSaver(f\"/home/luke/chess/python/datasets/\", log_level=log_level)\n",
    "  dataloader.enter_folder(dataset_name)\n",
    "\n",
    "  indexes = list(range(1, total_index + 1))\n",
    "\n",
    "  sf_file_means = []\n",
    "  sf_file_var = []\n",
    "  sf_file_max = []\n",
    "  my_file_means = []\n",
    "  my_file_var = []\n",
    "  my_file_max = []\n",
    "  both_file_means = []\n",
    "  both_file_var = []\n",
    "  both_file_max = []\n",
    "\n",
    "  for i in indexes:\n",
    "\n",
    "    loaded_data = dataloader.load(file_name, id=i)\n",
    "    data_sf = loaded_data[1]\n",
    "    data_my = loaded_data[2]\n",
    "    data_both = torch.cat((loaded_data[1].unsqueeze(1), loaded_data[2]), dim=1)\n",
    "\n",
    "    # clip large values\n",
    "    data_sf = torch.clip(data_sf, -clip_checkmate, clip_checkmate)\n",
    "    data_my = torch.clip(data_my, -clip_checkmate, clip_checkmate)\n",
    "    data_both = torch.clip(data_both, -clip_checkmate, clip_checkmate)\n",
    "\n",
    "    sf_file_means.append(torch.mean(data_sf).item())\n",
    "    sf_file_var.append(torch.var(data_sf).item())\n",
    "    sf_file_max.append(torch.max(torch.abs(data_sf)).item())\n",
    "    my_file_means.append(torch.mean(data_my).item())\n",
    "    my_file_var.append(torch.var(data_my).item())\n",
    "    my_file_max.append(torch.max(torch.abs(data_my)).item())\n",
    "    both_file_means.append(torch.mean(data_both).item())\n",
    "    both_file_var.append(torch.var(data_both).item())\n",
    "    both_file_max.append(torch.max(torch.abs(data_both)).item())\n",
    "\n",
    "  my_means = np.array(my_file_means)\n",
    "  my_overall_mean = np.mean(my_means)\n",
    "  my_overal_std = np.sqrt(np.mean(my_file_var) + np.mean(np.power(my_means - my_overall_mean, 2)))\n",
    "  my_max = np.max(my_file_max)\n",
    "\n",
    "  sf_means = np.array(sf_file_means)\n",
    "  sf_overall_mean = np.mean(sf_means)\n",
    "  sf_overal_std = np.sqrt(np.mean(sf_file_var) + np.mean(np.power(sf_means - sf_overall_mean, 2)))\n",
    "  sf_max = np.max(sf_file_max)\n",
    "\n",
    "  both_means = np.array(both_file_means)\n",
    "  both_overall_mean = np.mean(both_means)\n",
    "  both_overal_std = np.sqrt(np.mean(both_file_var) + np.mean(np.power(both_means - both_overall_mean, 2)))\n",
    "  both_max = np.max(both_file_max)\n",
    "\n",
    "  print(f\"Stockfish (mean, std, max) = ({sf_overall_mean:.3f}, {sf_overal_std:.3f}, {sf_max:.3f})\")\n",
    "  print(f\"My evals (mean, std, max) = ({my_overall_mean:.3f}, {my_overal_std:.3f}, {my_max:.3f})\")\n",
    "  print(f\"Both (mean, std, max) = ({both_overall_mean:.3f}, {both_overal_std:.3f}, {both_max:.3f})\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_dataset = False\n",
    "\n",
    "if shuffle_dataset:\n",
    "\n",
    "  old_dataset_name = \"dataset_v5_and_kaggle\"\n",
    "  new_datase_name = \"datasetv6\"\n",
    "  dataset_ind = 159\n",
    "\n",
    "  dataloader = ModelSaver(f\"/home/luke/chess/python/datasets/{dataset_name}\")\n",
    "  boards, evals, sq_evals = dataloader.load(\"data_torch\", id=dataset_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data, factors, clip=None):\n",
    "  \"\"\"\n",
    "  Normalise data based on [max, mean, std]\n",
    "  \"\"\"\n",
    "  max, mean, std = factors\n",
    "  d = ((data - mean) / std) / max\n",
    "  if clip is not None:\n",
    "    d = torch.clip(d, min=-clip, max=clip)\n",
    "  return d\n",
    "\n",
    "examine = False\n",
    "\n",
    "if examine:\n",
    "\n",
    "  factors = [23.927, -0.240, 0.355]\n",
    "  factors = [3, -0.240, 0.355]\n",
    "  norm_evals = normalise_data(dataset.evals, factors, clip=1)\n",
    "\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.hist(norm_evals.numpy(), bins=50)\n",
    "  plt.show()\n",
    "\n",
    "  print(torch.max(dataset.evals))\n",
    "  print(torch.min(dataset.evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexamine = False\n",
    "\n",
    "if rexamine:\n",
    "\n",
    "  # load all of the dataset files to examine the data distribution\n",
    "  max_values = []\n",
    "  mean_values = []\n",
    "  std_values = []\n",
    "  for i in range(1, 11):\n",
    "    this_data = datasaver.load(\"datasetv1\", id=i)\n",
    "    this_data.normalise_evaluations()\n",
    "    max_values.append(this_data.norm_factor[0])\n",
    "    mean_values.append(this_data.norm_factor[1])\n",
    "    std_values.append(this_data.norm_factor[2])\n",
    "\n",
    "  true_max = np.max(max_values)\n",
    "  avg_mean = np.mean(mean_values)\n",
    "  avg_std = np.mean(std_values)\n",
    "\n",
    "  print(f\"True max = {true_max:.3f}, true mean = {avg_mean:.3f}, average std = {avg_std:.3f}\")\n",
    "\n",
    "  norm_factors = [true_max, avg_mean, avg_std]\n",
    "\n",
    "else:\n",
    "  # True max = 23.927, true mean = -0.240, average std = 0.355\n",
    "  norm_factors = [23.927, -0.240, 0.355]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalise_data(data, factors):\n",
    "#   \"\"\"\n",
    "#   Normalise data based on [max, mean, std]\n",
    "#   \"\"\"\n",
    "#   max, mean, std = factors\n",
    "#   return ((data - mean) / std) / max\n",
    "\n",
    "# def denormalise_data(data, factors):\n",
    "#   \"\"\"\n",
    "#   Undo normalisation based on [max, mean, std]\n",
    "#   \"\"\"\n",
    "#   max, mean, std = factors\n",
    "#   return (data * max * std) + mean\n",
    "\n",
    "def normalise_data(data, factors):\n",
    "  \"\"\"\n",
    "  Normalise data based on [max, mean, std]\n",
    "  \"\"\"\n",
    "\n",
    "  # max, mean, std = self.norm_factors[:3]\n",
    "\n",
    "  clip, mean, std = factors\n",
    "  data = torch.clip(data, min=-clip, max=clip)\n",
    "  data = data - mean\n",
    "  data = data / std\n",
    "  return data\n",
    "  data = ((data - mean) / std)\n",
    "  return data\n",
    "\n",
    "def denormalise_data(data, factors):\n",
    "  \"\"\"\n",
    "  Undo normalisation based on [max, mean, std]\n",
    "  \"\"\"\n",
    "  clip, mean, std = factors\n",
    "  data = data * std\n",
    "  data = data + (mean / std)\n",
    "  return data\n",
    "  return (data * std) + mean\n",
    "\n",
    "def train_procedure(net, dataname, dataloader, data_inds, norm_factors,\n",
    "                    epochs=1, lr=1e-7, device=\"cuda\", batch_size=64,\n",
    "                    loss_style=\"MSE\"):\n",
    "  \"\"\"\n",
    "  Perform a training epoch for a given network based on data inputs\n",
    "  data_x, and correct outputs data_y\n",
    "  \"\"\"\n",
    "\n",
    "  # move onto the specified device\n",
    "  net.board_cnn.to(device)\n",
    "\n",
    "  # put the model in training mode\n",
    "  net.board_cnn.train()\n",
    "\n",
    "  if loss_style.lower() == \"mse\":\n",
    "    lossfcn = nn.MSELoss()\n",
    "  elif loss_style.lower() == \"l1\":\n",
    "    lossfcn = nn.L1Loss()\n",
    "  elif loss_style.lower() == \"huber\":\n",
    "    lossfcn = nn.HuberLoss()\n",
    "  else:\n",
    "    raise RuntimeError(f\"train_procedure() error: loss_style = {loss_style} not recognised\")\n",
    "\n",
    "  optim = torch.optim.Adam(net.board_cnn.parameters(), lr=lr)\n",
    "  \n",
    "  # each epoch, cover the entire training dataset\n",
    "  for i in range(epochs):\n",
    "\n",
    "    print(f\"Starting epoch {i + 1}.\")\n",
    "    total_batches = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # load the dataset in a series of slices\n",
    "    for slice_num, j in enumerate(data_inds):\n",
    "\n",
    "      # load this segment of the dataset\n",
    "      dataset = dataloader.load(dataname, id=j)\n",
    "      data_x = dataset.boards\n",
    "      data_y = dataset.evals\n",
    "\n",
    "      # import sys\n",
    "      # print(\"The size in bytes of data_x\", sys.getsizeof(data_x.storage()))\n",
    "      # print(\"The size in bytes of data_y\", sys.getsizeof(data_y.storage()))\n",
    "\n",
    "      # normalise y labels\n",
    "      data_y = normalise_data(data_y, norm_factors)\n",
    "\n",
    "      num_batches = len(data_x) // batch_size\n",
    "      total_batches += num_batches\n",
    "      rand_idx = torch.randperm(data_x.shape[0])\n",
    "      avg_loss = 0\n",
    "\n",
    "      print(f\"Starting slice {slice_num + 1} / {len(data_inds)}. There will be {num_batches} batches. \", end=\"\", flush=True)\n",
    "\n",
    "      # iterate through each batch for this slice of the dataset\n",
    "      for n in range(num_batches):\n",
    "\n",
    "        batch_x = data_x[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "        batch_y = data_y[rand_idx[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "        # go to cuda\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # use the model for a prediction and calculate loss\n",
    "        net_y = net.board_cnn(batch_x)\n",
    "        loss = lossfcn(net_y.squeeze(1), batch_y)\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        # if n % 500 == 0:\n",
    "        #   print(f\"Loss is {(avg_loss / (n + 1)) * 1000:.3f}, epoch {i + 1}, batch {n + 1} / {num_batches}\")\n",
    "\n",
    "      # this dataset slice is finished\n",
    "      epoch_loss += avg_loss\n",
    "      avg_loss = avg_loss / num_batches\n",
    "      avg_loss = avg_loss ** 0.5 * norm_factors[0] * norm_factors[2] # try to scale to original units\n",
    "      print(f\"Loss is {avg_loss:.3f}, during epoch {i + 1}, slice {slice_num + 1} / {len(data_inds)}\", flush=True)\n",
    "  \n",
    "    # this epoch is finished\n",
    "    epoch_loss = epoch_loss / total_batches\n",
    "    epoch_loss = epoch_loss ** 0.5 * norm_factors[0] * norm_factors[2] # try to scale to original units\n",
    "    print(f\"Epoch {i + 1} has finished after {total_batches} batches. Overall average loss = {epoch_loss:.3f}\", flush=True)\n",
    "\n",
    "  # finally, return the network that we have trained\n",
    "  return net\n",
    "\n",
    "do_train_procedure = False\n",
    "\n",
    "if do_train_procedure:\n",
    "\n",
    "  net = ChessNet(19)\n",
    "\n",
    "  device = \"cuda\"\n",
    "  epochs = 10\n",
    "  data_inds = list(range(1, 11))\n",
    "  lr = 1e-7\n",
    "\n",
    "  trained_net = train_procedure(\n",
    "    net=net,\n",
    "    dataname=\"datasetv1\",\n",
    "    dataloader=ModelSaver(\"/home/luke/chess/python/datasets/\", log_level=1),\n",
    "    data_inds=list(range(1, 11)),\n",
    "    norm_factors=[23.927, -0.240, 0.355], # [max, mean, std]\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    device=device    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /home/luke/chess/python/models/26-11-24/run_12-38_A1/network_010.lz4 with pickle ... finished\n",
      "Loading file /home/luke/chess/python/datasets/datasetv9/data_torch_180.lz4 with pickle ... finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "len(net_eval) = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m   sf_diff \u001b[38;5;241m=\u001b[39m this_sf_eval \u001b[38;5;241m-\u001b[39m net_my\n\u001b[1;32m     99\u001b[0m   my_diff \u001b[38;5;241m=\u001b[39m this_my_eval \u001b[38;5;241m-\u001b[39m net_my\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(net_eval) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(net_eval)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m net_print \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m    104\u001b[0m true_print \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: len(net_eval) = 1"
     ]
    }
   ],
   "source": [
    "def torch_to_board_vec(tensor):\n",
    "  \"\"\"\n",
    "  Convert a torch board vector into a cpp board vector\n",
    "  \"\"\"\n",
    "\n",
    "  boardvec = bf.BoardVectors()\n",
    "\n",
    "  boardvec.wP = list(tensor[0].reshape(64))\n",
    "  boardvec.wN = list(tensor[1].reshape(64))\n",
    "  boardvec.wB = list(tensor[2].reshape(64))\n",
    "  boardvec.wR = list(tensor[3].reshape(64))\n",
    "  boardvec.wQ = list(tensor[4].reshape(64))\n",
    "  boardvec.wK = list(tensor[5].reshape(64))\n",
    "  boardvec.bP = list(tensor[6].reshape(64))\n",
    "  boardvec.bN = list(tensor[7].reshape(64))\n",
    "  boardvec.bB = list(tensor[8].reshape(64))\n",
    "  boardvec.bR = list(tensor[9].reshape(64))\n",
    "  boardvec.bQ = list(tensor[10].reshape(64))\n",
    "  boardvec.bK = list(tensor[11].reshape(64))\n",
    "  boardvec.wKS = list(tensor[12].reshape(64))\n",
    "  boardvec.wQS = list(tensor[13].reshape(64))\n",
    "  boardvec.bKS = list(tensor[14].reshape(64))\n",
    "  boardvec.bQS = list(tensor[15].reshape(64))\n",
    "  boardvec.colour = list(tensor[16].reshape(64))\n",
    "\n",
    "  return boardvec\n",
    "\n",
    "loadexisting = True\n",
    "\n",
    "if loadexisting:\n",
    "\n",
    "  if False:\n",
    "    modelloader = ModelSaver(\"/home/luke/chess/python/models/\")\n",
    "    trained_net = modelloader.load(\"chessnet_model\", id=None)\n",
    "  else:\n",
    "    group = \"26-11-24\"\n",
    "    run = \"run_12-38_A2\"\n",
    "    modelloader = ModelSaver(f\"/home/luke/chess/python/models/{group}/{run}\")\n",
    "    trained_net = modelloader.load(\"network\", id=None)\n",
    "  \n",
    "  dataset_name = \"datasetv9\"\n",
    "  dataset_ind = 180\n",
    "  dataloader = ModelSaver(f\"/home/luke/chess/python/datasets/{dataset_name}\")\n",
    "  boards, evals, sq_evals = dataloader.load(\"data_torch\", id=dataset_ind)\n",
    "\n",
    "  device = \"cuda\"\n",
    "  trained_net.to(device)\n",
    "  boards = boards.to(device)\n",
    "  evals = evals.to(device)\n",
    "  sq_evals = sq_evals.to(device)\n",
    "\n",
    "  trained_net.eval()\n",
    "\n",
    "rand = False\n",
    "inds = list(range(len(evals)))\n",
    "if rand:\n",
    "  random.shuffle(inds)\n",
    "\n",
    "factors = [7, 0, 2.159]\n",
    "factors = [10, 0, 4]\n",
    "factors = [15, 0, 4.369]\n",
    "\n",
    "my_pred_vec = []\n",
    "sf_pred_vec = []\n",
    "my_diff_vec = []\n",
    "sf_diff_vec = []\n",
    "sf_vec = []\n",
    "my_vec = []\n",
    "\n",
    "avg_diff_sf = 0\n",
    "avg_diff_my = 0\n",
    "n = 2000\n",
    "inds = inds[:n]\n",
    "for i in inds:\n",
    "\n",
    "  # board piece rating comparison\n",
    "  net_eval = (trained_net(boards[i].unsqueeze(dim=0))).to(\"cpu\").squeeze(0)\n",
    "  net_eval = denormalise_data(net_eval, factors=factors)\n",
    "\n",
    "  this_board_vec = boards[i].to(\"cpu\")\n",
    "  this_sf_eval = evals[i].to(\"cpu\")\n",
    "  this_sq_evals = sq_evals[i].to(\"cpu\")\n",
    "  this_my_eval = torch.sum(this_sq_evals).item()\n",
    "\n",
    "  # board_vec = bf.FEN_to_board_vectors_with_eval(dataset.positions[i].fen_string)\n",
    "  # board_vec = torch.tensor(board_vec.sq_evals, dtype=torch.float) * 1e-3\n",
    "\n",
    "  if len(net_eval) == 65:\n",
    "    net_sf = net_eval[0].item()\n",
    "    net_my = torch.sum(net_eval[1:])\n",
    "    sf_diff = this_sf_eval - net_sf\n",
    "    my_diff = this_my_eval - net_my\n",
    "    net_eval = net_eval[1:]\n",
    "\n",
    "  elif len(net_eval) == 64: \n",
    "    net_sf = torch.sum(net_eval).detach()\n",
    "    net_my = torch.sum(net_eval).detach()\n",
    "    sf_diff = this_sf_eval - net_my\n",
    "    my_diff = this_my_eval - net_my\n",
    "\n",
    "  else: raise RuntimeError(f\"len(net_eval) = {len(net_eval)}\")\n",
    "\n",
    "  net_print = torch.zeros((8, 8))\n",
    "  true_print = torch.zeros((8, 8))\n",
    "  \n",
    "  torch.round(net_eval.reshape(8,8).detach(), decimals=2, out=net_print)\n",
    "  torch.round(this_sq_evals.reshape(8,8).detach(), decimals=2, out=true_print)\n",
    "\n",
    "  my_pred_vec.append(net_my.item())\n",
    "  my_diff_vec.append(my_diff.detach().item())\n",
    "  sf_pred_vec.append(net_sf)\n",
    "  sf_diff_vec.append(sf_diff.detach().item())\n",
    "  sf_vec.append(this_sf_eval.detach().item())\n",
    "  my_vec.append(this_my_eval)\n",
    "\n",
    "  avg_diff_sf += abs(sf_diff)\n",
    "  avg_diff_my += abs(my_diff)\n",
    "  \n",
    "  if n <= 50:\n",
    "    print(f\"Case {i + 1} / {n}.\", end=\" \")\n",
    "    if n < 6:\n",
    "      print(\"Board:\")\n",
    "      bf.print_board_vectors(torch_to_board_vec(this_board_vec))\n",
    "      # bf.print_FEN_board(dataset.positions[i].fen_string)\n",
    "      print(\"Net eval was\\n\", net_print)\n",
    "      print(\"Ground truth was\\n\", true_print)\n",
    "    print(f\"Stockfish: true eval = {this_sf_eval:.3f}, net eval = {net_sf:.3f}, difference = {this_sf_eval - net_sf:.3f}\")\n",
    "\n",
    "diff_sf = np.array(sf_diff_vec)\n",
    "mean_sf_diff = np.mean(np.abs(diff_sf))\n",
    "std_sf_diff = np.std(diff_sf)\n",
    "\n",
    "diff_my = np.array(my_diff_vec)\n",
    "mean_my_diff = np.mean(np.abs(diff_my))\n",
    "std_my_diff = np.std(diff_my)\n",
    "\n",
    "sf_vec = np.array(sf_vec)\n",
    "\n",
    "print(f\"The average difference from {n} samples is u={mean_my_diff:.3f} s={std_my_diff:.3f}, stockfish average difference is u={mean_sf_diff:.3f} s={std_sf_diff:.3f}\")\n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "# axs[0].hist(evals.detach().to(\"cpu\").numpy(), bins=40, range=(-10, 10))\n",
    "\n",
    "norm = normalise_data(torch.tensor(sf_vec), factors=factors)\n",
    "norm = norm.detach().numpy()\n",
    "\n",
    "axs[0][0].hist(sf_vec, bins=40, range=(-10, 10))\n",
    "axs[1][0].hist(sf_pred_vec, bins=40, range=(-10, 10))\n",
    "axs[2][0].hist(diff_sf, bins=40, range=(-10, 10))\n",
    "axs[0][1].hist(norm, bins=40)\n",
    "axs[1][1].hist(my_pred_vec, bins=40, range=(-10, 10))\n",
    "axs[2][1].hist(diff_my, bins=40, range=(-10, 10))\n",
    "axs[0][0].set_title(\"True stockfish evaluations\")\n",
    "axs[1][0].set_title(\"Stockfish predictions\")\n",
    "axs[2][0].set_title(\"Stockfish evaluation difference\")\n",
    "axs[0][1].set_title(\"True my evaluations\")\n",
    "axs[1][1].set_title(\"My evaluation predictions\")\n",
    "axs[2][1].set_title(\"My evaluation function difference\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: Total time 0.3s, so 0.265 ms per evaluation (approx 125.9 boards per s)\n",
      "Handcrafted: Total time 0.5s, so 0.524 ms per board (approx 1908.4 boards per s)\n"
     ]
    }
   ],
   "source": [
    "time_net = True\n",
    "\n",
    "if time_net:\n",
    "\n",
    "  timedevice = \"cpu\"\n",
    "  trained_net.board_cnn.eval()\n",
    "  trained_net.board_cnn.to(timedevice)\n",
    "  static_board = boards[0].to(timedevice).unsqueeze(dim=0)\n",
    "  num = 1000\n",
    "  j = 0\n",
    "\n",
    "  t1 = time.process_time()\n",
    "  for i in range(num):\n",
    "    trained_net.board_cnn(static_board)\n",
    "    j += 1\n",
    "    if j >= len(boards):\n",
    "      j = 0\n",
    "  t2 = time.process_time()\n",
    "\n",
    "  print(f\"Network: Total time {t2 - t1:.1f}s, so {((t2 - t1) / num) * 1e3:.3f} ms per evaluation (approx {1 / (30 * (t2 - t1) / num):.1f} boards per s)\")\n",
    "\n",
    "  t1 = time.process_time()\n",
    "  for i in range(num):\n",
    "    bf.generate_moves_FEN(dataset.positions[j].fen_string)\n",
    "    j += 1\n",
    "    if j >= len(dataset.boards):\n",
    "      j = 0\n",
    "  t2 = time.process_time()\n",
    "\n",
    "  print(f\"Handcrafted: Total time {t2 - t1:.1f}s, so {((t2 - t1) / num) * 1e3:.3f} ms per board (approx {1 / ((t2 - t1) / num):.1f} boards per s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace model, but move to the cpu before saving\n",
    "trained_net.to(\"cpu\")\n",
    "example = boards[0].unsqueeze(dim=0).to(\"cpu\")\n",
    "traced_net = torch.jit.trace(trained_net, example)\n",
    "\n",
    "traced_net.save(\"/home/luke/chess/python/models/traced_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
